{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As we've often discussed in the course, computers are dumb. I say this, writing weeks before the course actually meets, confident that we will say it at least once. Computers are very bad at inferring things, and your data needs to be clearly structured in order to work with it properly. Because of these difficulties, it is no accident that a number of different best practices have emerged for working with data. One of the most common formats for storing data that you will interact with is a Comma Separated Value (CSV) file. We will spend just a little time working with this file type today, as this form of data cleaning forms the basis for a lot of the work you are likely to do with Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A CSV file is, just as it sounds, a series of data fields separated by commas, often with headers at the top. And there is one data field per line:\n",
    "```\n",
    "id,last_name, first_name, cool?\n",
    "0,reed,ethan,so cool\n",
    "1,walsh,brandon,the coolest\n",
    "```\n",
    "And so on. By keeping careful track of our data in this way we are essentially creating a spreadsheet. This is good, because computers are quite good at reading spreadsheets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first we will need some data on our computer. Let's try these commands from the terminal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```bash\n",
    "$ mkdir csvs\n",
    "$ curl http://humanitiesprogramming.github.io/python/notebooks/csvs/basic.csv > basic.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first one should be pretty familiar, but what do you think the second command did? Let's break it down step by step.\n",
    "\n",
    "curl http://humanitiesprogramming.github.io/python/notebooks/csvs/basic.csv > basic.csv\n",
    "do_something the_thing_being_affected arrow filename\n",
    "\n",
    "The second piece is clearly a URL, and the fact that's a .csv extension suggests that it's some data of the filetype that we are discussing. The arrow suggests we're sending it somewhere. You got it! The curl command copies the contents of a URL. And the > sends the results of the thing on the left to the thing on the right. So we're saying \"Take the contents of this URL and save it in this filename that I've given you on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll pull in our newly created CSV file that we need. Notice the $'s have disappeared, so we're back in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'last_name', ' first_name', ' cool?'],\n",
       " ['0', 'reed', 'ethan', 'so cool'],\n",
       " ['1', 'walsh', 'brandon', 'the coolest']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "with open('csvs/basic.csv', 'r') as csvfile:\n",
    "    our_reader = csv.reader(csvfile)\n",
    "    names = [row for row in our_reader]\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I've done above is open the CSV file. Then, using the csv.reader function, we walk over the CSV file to see what is inside. The fourth line above is where we actually construct the data in a way we can work with it - we walk over every row in the table and smash those rows into a list called 'data'. At the end, data is a list of lists, and each sublist contains one row of the CSV file. We can use list indexing to explore parts of the data. We might be interested in the second row. Indexing once will give you the row you're interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', 'reed', 'ethan', 'so cool']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing twice will let you select first the row and then the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ethan'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since these are just lists, we can do anything to them that we might want to do to lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "5\n",
      "7\n",
      " first_name\n",
      "['brandon', 'ethan', ' first_name']\n"
     ]
    }
   ],
   "source": [
    "len(names)\n",
    "\n",
    "# find the length of each first name\n",
    "for row in names:\n",
    "    print(len(row[2]))\n",
    "    \n",
    "# find the longest first name\n",
    "longest = \"\"\n",
    "for row in names:\n",
    "    if len(row[2]) > len(longest):\n",
    "        longest = row[2]\n",
    "print(longest)\n",
    "\n",
    "# construct a new list consisting of only the last names we have here.\n",
    "last_names = [row[2] for row in names]\n",
    "last_names.reverse()\n",
    "print(last_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our CSV is just a list of lists, we could add to it by adding another row. And that's as easy as adding a new list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'last_name', ' first_name', ' cool?'],\n",
       " ['0', 'reed', 'ethan', 'so cool'],\n",
       " ['1', 'walsh', 'brandon', 'the coolest'],\n",
       " [2, 'wayne', 'graham', 'meh']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = [2,'wayne','graham','meh']\n",
    "names.append(new_row)\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could go on and on, adding to our CSV one row at a time. Let's try something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ca0d4006bc8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'fox'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'eliza'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SO COOL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma_row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "a_row = [3,'fox','eliza','SO COOL']\n",
    "names + a_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened? Take a look and see if you can tell.\n",
    "\n",
    "When we tried adding our new list to our collection of lists, it broke it apart and tried to add the individual items. You can tell this because the brackets disappear and we start getting rows of one item each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're starting to get to the point where we could use some more sophisticated ways of working with data. You might have noticed that I'm doing a LOT of looping. There are sometimes easier ways to work with your data than this. The way we're interacting with this CSV as a list of lists is really slow. There are other data structures that let you suck in a csv and, say, quickly get a particular column without having to loop over it first. If you're interested in learning better ways for interacting with there's a [great book on using Python for data science](https://github.com/jakevdp/PythonDataScienceHandbook) that I can't recommend enough. For the purposes of this lesson, though, we'll keep things simple.\n",
    "\n",
    "Another common thing that you'll want to do with CSV files is write them out. They're a common way of sharing data, and being able to get your data into them can offer a quick way to make your work more public. Rather than simply producing analyses of interesting data, you can also make your foundational resources public by sharing the CSV file. Let's start by getting something to write to the csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('csvs/practice.csv', 'w') as fout:\n",
    "    csvwriter = csv.writer(fout)\n",
    "    for i in range(0, 100, 10):\n",
    "        csvwriter.writerow([i, i + 5, i + 10, i + 15, i + 20, i + 25, i + 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we open a new file and, using a range, write out to that csv file. Did it work? We can check using the things we've already learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0', '5', '10', '15', '20', '25', '30'],\n",
       " ['10', '15', '20', '25', '30', '35', '40'],\n",
       " ['20', '25', '30', '35', '40', '45', '50'],\n",
       " ['30', '35', '40', '45', '50', '55', '60'],\n",
       " ['40', '45', '50', '55', '60', '65', '70'],\n",
       " ['50', '55', '60', '65', '70', '75', '80'],\n",
       " ['60', '65', '70', '75', '80', '85', '90'],\n",
       " ['70', '75', '80', '85', '90', '95', '100'],\n",
       " ['80', '85', '90', '95', '100', '105', '110'],\n",
       " ['90', '95', '100', '105', '110', '115', '120']]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('csvs/practice.csv', 'r') as fin:\n",
    "    our_reader = csv.reader(fin)\n",
    "    data = [row for row in our_reader]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using what we already know about indexing and element assignment in lists, we could modify particular elements and then write it back out to a CSV again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0', '5', '10', '15', '20', '25', '30'],\n",
       " ['10', '15', '20', '25', '30', '35', '40'],\n",
       " ['20', '25', '30', '35', '40', '45', 'Tony the cat'],\n",
       " ['30', '35', '40', '45', '50', 'Ethan', '60'],\n",
       " ['40', '45', '50', '55', '60', '65', '70'],\n",
       " ['50', '55', '60', '65', 'Brandon', '75', '80'],\n",
       " ['60', '65', '70', '75', '80', '85', '90'],\n",
       " ['70', '75', '80', '85', '90', '95', '100'],\n",
       " ['80', '85', '90', '95', '100', '105', '110'],\n",
       " ['90', '95', '100', '105', '110', '115', '120']]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[3][5] = 'Ethan'\n",
    "data[5][4] = 'Brandon'\n",
    "data[2][6] = 'Tony the cat'\n",
    "\n",
    "with open('csvs/practice.csv', 'w') as fout:\n",
    "    csvwriter = csv.writer(fout)\n",
    "    for row in data:\n",
    "        csvwriter.writerow(row)\n",
    "        \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out your 'practice.csv' file to see if it worked! Do you remember how to do this from the command line?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ cat csvs/practice.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But maybe you want to get a little more nuanced than this. After all, we put things in CSV files because we care about their organization. Working with lists of lists gets confusing quickly. There's a more nuanced way of reading these files using the DictWriter and DictReader classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('id', '0'), ('name', 'apple'), ('nutritious', 'True')]),\n",
       " OrderedDict([('id', '1'), ('name', 'banana'), ('nutritious', 'True')]),\n",
       " OrderedDict([('id', '2'), ('name', 'potato'), ('nutritious', 'True')]),\n",
       " OrderedDict([('id', '3'), ('name', \"ethan's heart\"), ('nutritious', 'True')]),\n",
       " OrderedDict([('id', '4'), ('name', 'puppy'), ('nutritious', 'False')])]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groceries = []\n",
    "with open('csvs/shopping.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        groceries.append(row)\n",
    "        \n",
    "groceries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still can't easily get to all the values for single column, but it does allow us to query by the column name when we're looking at a particular item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'potato'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groceries[2]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could get at a particular column by looping over the whole list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple\n",
      "banana\n",
      "potato\n",
      "ethan's heart\n",
      "puppy\n"
     ]
    }
   ],
   "source": [
    "for item in groceries:\n",
    "    print(item['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pandas package that I mentioned above is far better for this sort of thing, so check it out if you start doing complicated things with large amounts of data. Just as there is a DictReader class, there is also a DictWriter class that allows you to write that data back out to a file. Let's add some things to our grocery list and then write it to a new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tony = {'name': 'tony', 'nutritious': 'False', 'id': '5'}\n",
    "\n",
    "groceries.append(tony)\n",
    "\n",
    "with open('csvs/updated_groceries.csv', 'w') as fout:\n",
    "    column_names = ['id', 'name', 'nutritious']\n",
    "    dictwriter = csv.DictWriter(fout, fieldnames=column_names)\n",
    "    dictwriter.writeheader()\n",
    "    for row in groceries:\n",
    "        dictwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out your file and see if it worked. If we left any fields out in the tony item, it would still get added to the csv. It would just have blank spaces where those fields would be. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following exercises ask you to work with a dataset of historical press reports on Jack the Ripper that was scrapped from the [Jack the Ripper Casebook](http://www.casebook.org/). More information about the dataset can be found [here](http://walshbr.com/blog/2016/12/12/ripper-dataset/). I've pulled out just the first 300 or so rows from the corpus for you to work with. The CSV file lives at this URL - http://humanitiesprogramming.github.io/python/notebooks/csvs/ripper.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Adapt the above methods to get this CSV file onto your computer.\n",
    "2. Successfully read in the CSV and prove that you did it by printing out the column headings.\n",
    "3. Get all the texts of the press reports and store it in a variable called 'all_texts'\n",
    "4. What is the earliest date that an article was published?\n",
    "5. Write a new CSV with the same data, but lowercase all the texts for the press reports."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
